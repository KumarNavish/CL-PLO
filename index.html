<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CL-PLO | Theory and Validation</title>
    <link rel="stylesheet" href="./coreline.css" />
  </head>
  <body>
    <header class="hero">
      <div class="shell">
        <nav class="topbar">
          <a class="toplink" href="./strategy-comparison.html">Strategy Comparison</a>
          <span class="version">Coreline V5 Â· theory section rewrite</span>
        </nav>

        <h1>Constraint-aligned PEFT for continual portfolio learning</h1>
        <p class="lead">
          The central question is simple: can we keep adapting to regime drift without erasing the behavior that
          protects the portfolio in stress periods? This page answers that question in two stages. First, it explains
          the mechanisms. Then it shows the validation runs.
        </p>

        <div class="hero-actions">
          <a class="btn btn-primary" href="#foundations">Start With Theory</a>
          <a class="btn btn-ghost" href="#validation">Jump To Validation</a>
        </div>
      </div>
    </header>

    <main class="shell">
      <section id="foundations" class="section" aria-label="Foundations">
        <h2>1. Problem setup</h2>
        <p>
          Portfolio construction is held fixed. At each step, weights are obtained from the same constrained optimizer.
          What changes across methods is only the update rule for the adapter parameters that feed forecast inputs into
          that optimizer.
        </p>
        <pre>w_t = arg min_w -mu_hat_t^T w + gamma * w^T Sigma_hat_t w + lambda_tc * TC(w, w_{t-1})
subject to risk and drawdown constraints</pre>
        <p>
          This separation matters. It lets us compare update mechanisms cleanly, without conflating learning behavior
          with a different optimizer.
        </p>

        <h3>Assumptions used in the comparison</h3>
        <ul>
          <li>Regime drift is persistent, but stress periods appear intermittently.</li>
          <li>Adapters should absorb new information while the backbone remains frozen.</li>
          <li>A stress-anchor buffer approximates behavior that should not regress.</li>
          <li>Deployment quality is judged by retention, drawdown, and adaptation cost together.</li>
        </ul>

        <p>
          Before running any experiment, the expected ordering is: naive should adapt fastest; anchor should be more
          stable; projection should preserve stress behavior most strongly, at the cost of some drift-fit flexibility.
        </p>
      </section>

      <section id="methods" class="section" aria-label="Method mechanics">
        <h2>2. Method mechanics</h2>
        <p>
          The three methods below differ only in how they update adapter gradients. Each method description is
          deliberately explicit: objective, constraint, what is preserved, and what is allowed to move.
        </p>

        <article class="method">
          <h3>Method A: Naive continual update</h3>
          <p>
            This baseline follows the current drift objective directly. It is usually the most responsive method, but it
            has no explicit memory of stress behavior.
          </p>
          <dl>
            <div><dt>Objective</dt><dd>Minimize current drift loss.</dd></div>
            <div><dt>Constraint</dt><dd>No retention constraint in gradient space.</dd></div>
            <div><dt>Preserves</dt><dd>Short-horizon fit to the present regime.</dd></div>
            <div><dt>Allows to change</dt><dd>All adapter directions, including stress-sensitive directions.</dd></div>
          </dl>
          <pre>g = grad L_drift
theta_{t+1} = theta_t - eta * g</pre>
          <figure class="mechanism">
            <figcaption>Update path</figcaption>
            <div class="flow">Drift batch -> Gradient -> Adapter update -> Forecasts -> Optimizer -> Weights</div>
          </figure>
          <p class="refs">
            References:
            <a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noreferrer">LoRA (Hu et al., 2022)</a>,
            <a href="https://dl.acm.org/doi/10.1145/2638548" target="_blank" rel="noreferrer">Online Portfolio Selection survey</a>.
          </p>
        </article>

        <article class="method">
          <h3>Method B: Anchor-regularized update</h3>
          <p>
            This variant adds a soft memory term from stress anchors. It usually reduces forgetting, but still permits
            destructive updates when drift pressure is strong enough.
          </p>
          <dl>
            <div><dt>Objective</dt><dd>Fit drift while penalizing anchor regression.</dd></div>
            <div><dt>Constraint</dt><dd>Soft retention through the anchor weight beta.</dd></div>
            <div><dt>Preserves</dt><dd>Part of stress behavior through replay pressure.</dd></div>
            <div><dt>Allows to change</dt><dd>Any direction if compensated by loss tradeoff.</dd></div>
          </dl>
          <pre>L = L_drift + beta * L_anchor
g = grad L
theta_{t+1} = theta_t - eta * g</pre>
          <figure class="mechanism">
            <figcaption>Update path</figcaption>
            <div class="flow">Drift batch + Anchor buffer -> Weighted loss -> Gradient -> Adapter update -> Optimizer</div>
          </figure>
          <p class="refs">
            References:
            <a href="https://openreview.net/forum?id=Hkf2_sC5FX" target="_blank" rel="noreferrer">A-GEM (Chaudhry et al., 2019)</a>,
            <a href="https://proceedings.neurips.cc/paper/2012/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html" target="_blank" rel="noreferrer">Online optimization with constraints</a>.
          </p>
        </article>

        <article class="method">
          <h3>Method C: Anchor + gradient projection</h3>
          <p>
            This is the proposed mechanism. Instead of only penalizing harmful movement, it projects the drift gradient
            onto a feasible region defined by the anchor direction. In practice, that makes retention a geometric
            condition rather than a soft preference.
          </p>
          <dl>
            <div><dt>Objective</dt><dd>Stay close to drift gradient while satisfying anchor safety.</dd></div>
            <div><dt>Constraint</dt><dd>Hard inequality in gradient space.</dd></div>
            <div><dt>Preserves</dt><dd>Anchor-consistent stress response by construction.</dd></div>
            <div><dt>Allows to change</dt><dd>Directions compatible with the projection constraint.</dd></div>
          </dl>
          <pre>g_tilde = arg min_g 0.5 * ||g - g_drift||^2
subject to &lt;g, g_anchor&gt; >= -eps

theta_{t+1} = theta_t - eta * g_tilde</pre>
          <figure class="mechanism">
            <figcaption>Update path</figcaption>
            <div class="flow">Drift gradient + Anchor gradient -> Projection step -> Safe update -> Optimizer</div>
          </figure>
          <p class="refs">
            References:
            <a href="https://openreview.net/forum?id=Hkf2_sC5FX" target="_blank" rel="noreferrer">A-GEM</a>,
            <a href="https://arxiv.org/abs/2405.13383" target="_blank" rel="noreferrer">Gradient projection for continual PEFT</a>,
            <a href="https://web.stanford.edu/~boyd/papers/pdf/cvx_portfolio.pdf" target="_blank" rel="noreferrer">Convex portfolio control</a>.
          </p>
        </article>
      </section>

      <section id="validation" class="section" aria-label="Validation">
        <h2>3. Validation</h2>
        <p>
          These runs are evidence checks, not discovery. They test whether measured ordering agrees with the mechanism
          claims above.
        </p>

        <article id="expectation-check" class="expectation-check"></article>

        <div class="control-stack">
          <div class="preset-row">
            <button id="apply-quick" class="btn btn-ghost" type="button">Quick</button>
            <button id="apply-proposal" class="btn btn-ghost" type="button">Default</button>
            <button id="apply-stress" class="btn btn-ghost" type="button">Stress+</button>
          </div>

          <form id="config-form" class="knob-grid">
            <label>Update steps<input name="steps" type="number" step="1" /></label>
            <label>Anchor weight<input name="anchorBeta" type="number" step="0.01" /></label>
            <label>Stress frequency<input name="pStress" type="number" step="0.01" /></label>
            <label>LoRA rank<input name="loraRank" type="number" step="1" /></label>
            <label>Seed<input name="seed" type="number" step="1" /></label>
          </form>

          <div class="action-row">
            <button id="run-demo" class="btn btn-primary" type="button">Run Validation</button>
            <button id="reset-form" class="btn btn-ghost" type="button">Reset</button>
            <button id="export-run" class="btn btn-ghost" type="button">Export JSON</button>
          </div>
        </div>

        <div class="run-status">
          <p id="status-line">Ready.</p>
          <div class="progress-track"><div id="progress-fill"></div></div>
        </div>

        <article id="decision-card" class="decision-card"></article>

        <div id="impact-kpis" class="kpi-row"></div>

        <div class="chart-grid">
          <article>
            <h3>Impact vs naive</h3>
            <canvas id="impact-chart" class="chart-canvas"></canvas>
          </article>
          <article>
            <h3>Equity curves</h3>
            <canvas id="equity-chart" class="chart-canvas"></canvas>
          </article>
        </div>

        <article class="table-wrap">
          <h3>Method scoreboard</h3>
          <table id="method-table" class="method-table"></table>
        </article>

        <article id="takeaway" class="takeaway"></article>
      </section>
    </main>

    <footer class="footer">
      <p>Theory first. Validation second.</p>
    </footer>

    <script type="module" src="./src/main.js"></script>
  </body>
</html>
