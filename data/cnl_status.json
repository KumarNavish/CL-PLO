{
  "collected_at_utc": "2026-02-12T13:21:16.876207+00:00",
  "host": "dmi-fibonacci",
  "cwd": "/users/staff/dmi-dmi/kumar0002/Collaborative-Neuron-Learning",
  "status": "ok",
  "project_id": "fibonacci-cnl",
  "project_name": "Fibonacci CNL SmolLM",
  "cards": [
    {
      "label": "Remote Host",
      "value": "dmi-fibonacci"
    },
    {
      "label": "Remote CWD",
      "value": "/users/staff/dmi-dmi/kumar0002/Collaborative-Neuron-Learning"
    },
    {
      "label": "Collected At (UTC)",
      "value": "2026-02-12T13:21:16.876207+00:00"
    },
    {
      "label": "Model Tag",
      "value": "SmolLM2-360M-Instruct"
    },
    {
      "label": "Merged Summary",
      "value": "results/smollm_full_baselines_summary.csv"
    },
    {
      "label": "Coordinator Log",
      "value": "logs/full_smollm_baselines_20260211_143202.out"
    }
  ],
  "tables": [
    {
      "title": "Training Jobs",
      "columns": [
        {
          "key": "dataset",
          "label": "dataset"
        },
        {
          "key": "use_freeze",
          "label": "use_freeze"
        },
        {
          "key": "status",
          "label": "status"
        },
        {
          "key": "epoch",
          "label": "epoch"
        },
        {
          "key": "train_avg_loss",
          "label": "train_avg_loss"
        },
        {
          "key": "wrong_to_correct",
          "label": "wrong_to_correct"
        },
        {
          "key": "correct_to_wrong",
          "label": "correct_to_wrong"
        },
        {
          "key": "elapsed",
          "label": "elapsed"
        }
      ],
      "rows": [
        {
          "dataset": "arc_c",
          "use_freeze": 1,
          "status": "done",
          "epoch": "25",
          "train_avg_loss": "2.585893348826598",
          "wrong_to_correct": "38",
          "correct_to_wrong": "40",
          "elapsed": "1:07:37",
          "log_path": "logs/train_arc_c_usefreeze1.log",
          "summary_path": "zero_ckpts/arc_c_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
        },
        {
          "dataset": "arc_c",
          "use_freeze": 0,
          "status": "done",
          "epoch": "25",
          "train_avg_loss": "1.3083139358742",
          "wrong_to_correct": "298",
          "correct_to_wrong": "254",
          "elapsed": "44:40.38",
          "log_path": "logs/train_arc_c_usefreeze0.log",
          "summary_path": "zero_ckpts/arc_c_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
        },
        {
          "dataset": "csqa",
          "use_freeze": 1,
          "status": "done",
          "epoch": "25",
          "train_avg_loss": "2.4547550374364793",
          "wrong_to_correct": "23",
          "correct_to_wrong": "32",
          "elapsed": "57:54.81",
          "log_path": "logs/train_csqa_usefreeze1.log",
          "summary_path": "zero_ckpts/csqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
        },
        {
          "dataset": "csqa",
          "use_freeze": 0,
          "status": "done",
          "epoch": "25",
          "train_avg_loss": "1.2850813132517158",
          "wrong_to_correct": "236",
          "correct_to_wrong": "257",
          "elapsed": "37:33.90",
          "log_path": "logs/train_csqa_usefreeze0.log",
          "summary_path": "zero_ckpts/csqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
        },
        {
          "dataset": "medqa",
          "use_freeze": 1,
          "status": "done",
          "epoch": "25",
          "train_avg_loss": "2.2436387252039323",
          "wrong_to_correct": "83",
          "correct_to_wrong": "82",
          "elapsed": "1:17:30",
          "log_path": "logs/train_medqa_usefreeze1.log",
          "summary_path": "zero_ckpts/medqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
        },
        {
          "dataset": "medqa",
          "use_freeze": 0,
          "status": "done",
          "epoch": "25",
          "train_avg_loss": "1.4639859721219466",
          "wrong_to_correct": "261",
          "correct_to_wrong": "264",
          "elapsed": "50:47.39",
          "log_path": "logs/train_medqa_usefreeze0.log",
          "summary_path": "zero_ckpts/medqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
        },
        {
          "dataset": "mmlu",
          "use_freeze": 1,
          "status": "done",
          "epoch": "25",
          "train_avg_loss": "2.5952079296872324",
          "wrong_to_correct": "54",
          "correct_to_wrong": "68",
          "elapsed": "1:21:03",
          "log_path": "logs/train_mmlu_usefreeze1.log",
          "summary_path": "zero_ckpts/mmlu_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
        },
        {
          "dataset": "mmlu",
          "use_freeze": 0,
          "status": "done",
          "epoch": "25",
          "train_avg_loss": "1.3213374216337592",
          "wrong_to_correct": "347",
          "correct_to_wrong": "331",
          "elapsed": "1:01:46",
          "log_path": "logs/train_mmlu_usefreeze0.log",
          "summary_path": "zero_ckpts/mmlu_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
        }
      ]
    },
    {
      "title": "Table 1",
      "paper_table": "table1",
      "caption": "Relationship between gradient similarity and catastrophic forgetting. Results are reported as Number of forgotten questions (Percentage). Samples with negative gradient similarity are ranked by magnitude: top 1/3 are Sim, bottom 1/3 are Dissim.",
      "dataset_order": [
        "mmlu",
        "medqa",
        "arc_c",
        "csqa"
      ],
      "columns": [
        {
          "key": "model",
          "label": "MODEL"
        }
      ],
      "rows": [
        {
          "model": "SmolLM 360M",
          "mmlu_dissimilar": "102 (33.12%)",
          "mmlu_similar": "102 (33.12%)",
          "medqa_dissimilar": "75 (27.68%)",
          "medqa_similar": "90 (33.21%)",
          "arc_c_dissimilar": "81 (33.20%)",
          "arc_c_similar": "81 (33.20%)",
          "csqa_dissimilar": "83 (33.07%)",
          "csqa_similar": "83 (33.07%)"
        }
      ]
    },
    {
      "title": "Table 2",
      "paper_table": "table2",
      "caption": "Distribution of collaborative neurons (COLL) and conflicting neurons (CONF). PROP denotes neuron-type proportion. GRAD denotes gradient similarity sum for that type. TOTAL denotes the gradient similarity sum over all neurons.",
      "dataset_order": [
        "mmlu",
        "medqa",
        "arc_c",
        "csqa"
      ],
      "model": "SmolLM 360M",
      "rows": [
        {
          "metric": "PROP",
          "mmlu_coll": "20.3%",
          "mmlu_conf": "79.7%",
          "medqa_coll": "39.5%",
          "medqa_conf": "60.5%",
          "arc_c_coll": "18.9%",
          "arc_c_conf": "81.0%",
          "csqa_coll": "22.7%",
          "csqa_conf": "77.3%"
        },
        {
          "metric": "GRAD",
          "mmlu_coll": "+0.34",
          "mmlu_conf": "+99.66",
          "medqa_coll": "+4.92",
          "medqa_conf": "+95.08",
          "arc_c_coll": "+0.16",
          "arc_c_conf": "+99.84",
          "csqa_coll": "+0.51",
          "csqa_conf": "+99.49"
        },
        {
          "metric": "TOTAL",
          "mmlu_total": "100.00",
          "medqa_total": "100.00",
          "arc_c_total": "100.00",
          "csqa_total": "100.00"
        }
      ],
      "columns": [
        {
          "key": "metric",
          "label": "Metric"
        }
      ]
    },
    {
      "title": "Table 3",
      "paper_table": "table3",
      "caption": "Effectiveness of knowledge injection using FT and CNL. Results are reported as Number of questions (Percentage). FT tends to forget previously mastered knowledge, while CNL induces negligible catastrophic forgetting.",
      "dataset_order": [
        "mmlu",
        "medqa",
        "arc_c",
        "csqa"
      ],
      "model": "SmolLM 360M",
      "columns": [
        {
          "key": "model",
          "label": "MODEL"
        },
        {
          "key": "method",
          "label": "METHOD"
        },
        {
          "key": "mmlu_learned",
          "label": "MMLU LEARNED"
        },
        {
          "key": "mmlu_forgot",
          "label": "MMLU FORGOT"
        },
        {
          "key": "medqa_learned",
          "label": "MedQA LEARNED"
        },
        {
          "key": "medqa_forgot",
          "label": "MedQA FORGOT"
        },
        {
          "key": "arc_c_learned",
          "label": "ARC-C LEARNED"
        },
        {
          "key": "arc_c_forgot",
          "label": "ARC-C FORGOT"
        },
        {
          "key": "csqa_learned",
          "label": "CSQA LEARNED"
        },
        {
          "key": "csqa_forgot",
          "label": "CSQA FORGOT"
        }
      ],
      "rows": [
        {
          "model": "SmolLM 360M",
          "method": "FT",
          "mmlu_learned": "347 (29.51%)",
          "mmlu_forgot": "331 (87.80%)",
          "medqa_learned": "261 (27.13%)",
          "medqa_forgot": "264 (85.16%)",
          "arc_c_learned": "298 (30.22%)",
          "arc_c_forgot": "254 (89.44%)",
          "csqa_learned": "236 (29.03%)",
          "csqa_forgot": "257 (90.81%)"
        },
        {
          "model": "SmolLM 360M",
          "method": "CNL",
          "mmlu_learned": "54 (4.59%)",
          "mmlu_forgot": "68 (18.04%)",
          "medqa_learned": "83 (8.63%)",
          "medqa_forgot": "82 (26.45%)",
          "arc_c_learned": "38 (3.85%)",
          "arc_c_forgot": "40 (14.08%)",
          "csqa_learned": "23 (2.83%)",
          "csqa_forgot": "32 (11.31%)"
        }
      ]
    },
    {
      "title": "Table 4",
      "paper_table": "table4",
      "caption": "Impact of different optimizers on catastrophic forgetting. Results are reported as Number of questions (Percentage).",
      "dataset_order": [
        "mmlu",
        "medqa",
        "arc_c",
        "csqa"
      ],
      "model": "SmolLM 360M",
      "target_epoch": 25,
      "columns": [
        {
          "key": "optimizer",
          "label": "OPTIMIZER"
        },
        {
          "key": "method",
          "label": "METHOD"
        }
      ],
      "rows": [
        {
          "optimizer": "SGD",
          "method": "FT",
          "mmlu_learned": "347 (29.51%)",
          "mmlu_forgot": "331 (87.80%)",
          "medqa_learned": "261 (27.13%)",
          "medqa_forgot": "264 (85.16%)",
          "arc_c_learned": "298 (30.22%)",
          "arc_c_forgot": "254 (89.44%)",
          "csqa_learned": "236 (29.03%)",
          "csqa_forgot": "257 (90.81%)"
        },
        {
          "optimizer": "SGD",
          "method": "CNL",
          "mmlu_learned": "54 (4.59%)",
          "mmlu_forgot": "68 (18.04%)",
          "medqa_learned": "83 (8.63%)",
          "medqa_forgot": "82 (26.45%)",
          "arc_c_learned": "38 (3.85%)",
          "arc_c_forgot": "40 (14.08%)",
          "csqa_learned": "23 (2.83%)",
          "csqa_forgot": "32 (11.31%)"
        },
        {
          "optimizer": "Momentum",
          "method": "FT",
          "mmlu_learned": "PENDING",
          "mmlu_forgot": "PENDING",
          "medqa_learned": "PENDING",
          "medqa_forgot": "PENDING",
          "arc_c_learned": "PENDING",
          "arc_c_forgot": "PENDING",
          "csqa_learned": "PENDING",
          "csqa_forgot": "PENDING"
        },
        {
          "optimizer": "Momentum",
          "method": "CNL",
          "mmlu_learned": "PENDING",
          "mmlu_forgot": "PENDING",
          "medqa_learned": "PENDING",
          "medqa_forgot": "PENDING",
          "arc_c_learned": "PENDING",
          "arc_c_forgot": "PENDING",
          "csqa_learned": "23 (2.83%)",
          "csqa_forgot": "32 (11.31%)"
        },
        {
          "optimizer": "Adam",
          "method": "FT",
          "mmlu_learned": "PENDING",
          "mmlu_forgot": "PENDING",
          "medqa_learned": "PENDING",
          "medqa_forgot": "PENDING",
          "arc_c_learned": "PENDING",
          "arc_c_forgot": "PENDING",
          "csqa_learned": "PENDING",
          "csqa_forgot": "PENDING"
        },
        {
          "optimizer": "Adam",
          "method": "CNL",
          "mmlu_learned": "PENDING",
          "mmlu_forgot": "PENDING",
          "medqa_learned": "PENDING",
          "medqa_forgot": "PENDING",
          "arc_c_learned": "PENDING",
          "arc_c_forgot": "PENDING",
          "csqa_learned": "23 (2.83%)",
          "csqa_forgot": "31 (10.95%)"
        },
        {
          "optimizer": "AdamW",
          "method": "FT",
          "mmlu_learned": "PENDING",
          "mmlu_forgot": "PENDING",
          "medqa_learned": "PENDING",
          "medqa_forgot": "PENDING",
          "arc_c_learned": "PENDING",
          "arc_c_forgot": "PENDING",
          "csqa_learned": "PENDING",
          "csqa_forgot": "PENDING"
        },
        {
          "optimizer": "AdamW",
          "method": "CNL",
          "mmlu_learned": "PENDING",
          "mmlu_forgot": "PENDING",
          "medqa_learned": "PENDING",
          "medqa_forgot": "PENDING",
          "arc_c_learned": "PENDING",
          "arc_c_forgot": "PENDING",
          "csqa_learned": "23 (2.83%)",
          "csqa_forgot": "31 (10.95%)"
        }
      ]
    },
    {
      "title": "GPU",
      "columns": [
        {
          "key": "gpu",
          "label": "gpu"
        },
        {
          "key": "name",
          "label": "name"
        },
        {
          "key": "memory_used",
          "label": "memory_used"
        },
        {
          "key": "memory_total",
          "label": "memory_total"
        },
        {
          "key": "utilization",
          "label": "utilization"
        }
      ],
      "rows": [
        {
          "gpu": "0",
          "name": "NVIDIA GeForce RTX 3090",
          "memory_used": "22713 MiB",
          "memory_total": "24576 MiB",
          "utilization": "22 %"
        },
        {
          "gpu": "1",
          "name": "NVIDIA GeForce RTX 3090",
          "memory_used": "9174 MiB",
          "memory_total": "24576 MiB",
          "utilization": "26 %"
        },
        {
          "gpu": "2",
          "name": "NVIDIA GeForce RTX 3090",
          "memory_used": "9174 MiB",
          "memory_total": "24576 MiB",
          "utilization": "20 %"
        },
        {
          "gpu": "3",
          "name": "NVIDIA GeForce RTX 3090",
          "memory_used": "9172 MiB",
          "memory_total": "24576 MiB",
          "utilization": "23 %"
        },
        {
          "gpu": "4",
          "name": "NVIDIA GeForce RTX 3090",
          "memory_used": "5788 MiB",
          "memory_total": "24576 MiB",
          "utilization": "94 %"
        },
        {
          "gpu": "5",
          "name": "NVIDIA GeForce RTX 3090",
          "memory_used": "9726 MiB",
          "memory_total": "24576 MiB",
          "utilization": "24 %"
        },
        {
          "gpu": "6",
          "name": "NVIDIA GeForce RTX 3090",
          "memory_used": "9172 MiB",
          "memory_total": "24576 MiB",
          "utilization": "29 %"
        },
        {
          "gpu": "7",
          "name": "NVIDIA GeForce RTX 3090",
          "memory_used": "9172 MiB",
          "memory_total": "24576 MiB",
          "utilization": "46 %"
        }
      ]
    },
    {
      "title": "Merged Summary",
      "columns": [
        {
          "key": "dataset",
          "label": "dataset"
        },
        {
          "key": "use_freeze",
          "label": "use_freeze"
        },
        {
          "key": "epoch",
          "label": "epoch"
        },
        {
          "key": "train_avg_loss",
          "label": "train_avg_loss"
        },
        {
          "key": "wrong_to_correct",
          "label": "wrong_to_correct"
        },
        {
          "key": "correct_to_wrong",
          "label": "correct_to_wrong"
        },
        {
          "key": "elapsed",
          "label": "elapsed"
        },
        {
          "key": "summary_csv",
          "label": "summary_csv"
        }
      ],
      "rows": [
        {
          "dataset": "arc_c",
          "use_freeze": "1",
          "epoch": "25",
          "train_avg_loss": "2.585893348826598",
          "wrong_to_correct": "38",
          "correct_to_wrong": "40",
          "elapsed": "1:07:37",
          "summary_csv": "zero_ckpts/arc_c_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
        },
        {
          "dataset": "arc_c",
          "use_freeze": "0",
          "epoch": "25",
          "train_avg_loss": "1.3083139358742",
          "wrong_to_correct": "298",
          "correct_to_wrong": "254",
          "elapsed": "44:40.38",
          "summary_csv": "zero_ckpts/arc_c_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
        },
        {
          "dataset": "csqa",
          "use_freeze": "1",
          "epoch": "25",
          "train_avg_loss": "2.4547550374364793",
          "wrong_to_correct": "23",
          "correct_to_wrong": "32",
          "elapsed": "57:54.81",
          "summary_csv": "zero_ckpts/csqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
        },
        {
          "dataset": "csqa",
          "use_freeze": "0",
          "epoch": "25",
          "train_avg_loss": "1.2850813132517158",
          "wrong_to_correct": "236",
          "correct_to_wrong": "257",
          "elapsed": "37:33.90",
          "summary_csv": "zero_ckpts/csqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
        },
        {
          "dataset": "medqa",
          "use_freeze": "1",
          "epoch": "25",
          "train_avg_loss": "2.2436387252039323",
          "wrong_to_correct": "83",
          "correct_to_wrong": "82",
          "elapsed": "1:17:30",
          "summary_csv": "zero_ckpts/medqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
        },
        {
          "dataset": "medqa",
          "use_freeze": "0",
          "epoch": "25",
          "train_avg_loss": "1.4639859721219466",
          "wrong_to_correct": "261",
          "correct_to_wrong": "264",
          "elapsed": "50:47.39",
          "summary_csv": "zero_ckpts/medqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
        },
        {
          "dataset": "mmlu",
          "use_freeze": "1",
          "epoch": "25",
          "train_avg_loss": "2.5952079296872324",
          "wrong_to_correct": "54",
          "correct_to_wrong": "68",
          "elapsed": "1:21:03",
          "summary_csv": "zero_ckpts/mmlu_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
        },
        {
          "dataset": "mmlu",
          "use_freeze": "0",
          "epoch": "25",
          "train_avg_loss": "1.3213374216337592",
          "wrong_to_correct": "347",
          "correct_to_wrong": "331",
          "elapsed": "1:01:46",
          "summary_csv": "zero_ckpts/mmlu_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
        }
      ]
    }
  ],
  "texts": [
    {
      "title": "Table 1 Status",
      "content": "Rendered datasets: MMLU, MedQA, ARC-C, CSQA\nPending datasets: none\nNegative grad-dot totals: MMLU=308, MedQA=271, ARC-C=244, CSQA=251"
    },
    {
      "title": "Table 2 Status",
      "content": "Rendered datasets: MMLU, MedQA, ARC-C, CSQA\nPending datasets: none"
    },
    {
      "title": "Table 3 Status",
      "content": "Rendered datasets: MMLU, MedQA, ARC-C, CSQA\nPending datasets (waiting for epoch 25 on all methods): none"
    },
    {
      "title": "Table 4 Status",
      "content": "Completed entries: 11/32 (target epoch 25).\nPending entries: 21\nPending preview: Momentum/FT/MMLU, Momentum/FT/MedQA, Momentum/FT/ARC-C, Momentum/FT/CSQA, Momentum/CNL/MMLU, Momentum/CNL/MedQA, Momentum/CNL/ARC-C, Adam/FT/MMLU, +13 more"
    },
    {
      "title": "Paper Comparison Appendix (Simple)",
      "content": "Quick read (simple language):\n\n1) What these results mean in practical and conceptual terms:\n- Practical: Forgetting drops a lot with CNL (FT 88.30% -> CNL 17.47%).\n- Practical: New learning is also much lower with CNL (FT 28.97% -> CNL 4.98%).\n- Conceptual: On this small model, CNL behaves like a strong stability control. It protects old knowledge, but it also limits plasticity.\n- Mechanism hint from Table 1: Sim has more forgetting in 1/4 datasets.\n- Mechanism hint from Table 2: Conflicting neurons are more common in 4/4 datasets.\n\n2) How this compares to the original paper (larger models):\n- Direction matches: CNL still reduces forgetting compared with FT.\n- In this SmolLM run, forgetting is about 80.2% lower with CNL, but learning is about 82.8% lower.\n- Difference from paper trend: the large-model paper shows strong forgetting control without such a large learning drop.\n- So this is a partial reproduction, not a full quantitative match.\n\n3) Are trends consistent with the original findings? If not, why might they differ?\n- Partly consistent: CNL < FT on forgetting.\n- Partly inconsistent: CNL learning is much lower here than the paper suggests.\n- Likely reasons:\n- Small model has less spare capacity, so stability controls can block learning more strongly.\n- Same training recipe from bigger models may not be optimal at this scale.\n- One model size and one config are not enough to average out run variance.\n- Table 2 values are normalized in this pipeline, while the paper reports signed sums.\n\n4) What we can and cannot conclude (scalability, robustness, mechanism):\n- Can conclude (robustness): CNL robustly reduces forgetting versus FT in this run.\n- Can conclude (mechanism, directional): conflict-heavy structure still appears (Table 2), but weaker.\n- Cannot conclude (scalability): we cannot claim large-model behavior from one small-model setting.\n- Cannot conclude (mechanism, strict): we need exact metric parity and multi-seed checks.\n- Cannot conclude (final quality): this is a strong diagnostic result, not the final endpoint."
    },
    {
      "title": "Coordinator Log Tail (logs/full_smollm_baselines_20260211_143202.out)",
      "content": "Using GPUs: 6, 7,\nModel: HuggingFaceTB/SmolLM2-360M-Instruct\nDatasets: arc_c csqa medqa mmlu\narc_c rows 1270\ncsqa rows 1096\nmedqa rows 1272\nmmlu rows 1553\nWROTE results/smollm_full_baselines_summary.csv\nCompleted full SmolLM CNL+vanilla batch."
    },
    {
      "title": "Runner Process",
      "content": "1256051 /bin/sh -c pgrep -af run_full_smollm_baselines_remote.sh"
    },
    {
      "title": "Training Processes",
      "content": "ERROR: Command 'pgrep -af python3\\ sft/sft.py' returned non-zero exit status 1."
    },
    {
      "title": "Inference Processes",
      "content": "ERROR: Command 'pgrep -af python3\\ infer/infer.py' returned non-zero exit status 1."
    },
    {
      "title": "Dashboard Processes",
      "content": "663829 bash -c cd ~/Collaborative-Neuron-Learning && . logs/dashboard_auth.env && nohup python3 scripts/live_dashboard.py --host 127.0.0.1 --port 18080 --base_dir . --auth_user \"$DASHBOARD_USER\" --auth_password *** > logs/live_dashboard_auth.out 2>&1 < /dev/null & echo DASH_PID:$!\n663830 python3 scripts/live_dashboard.py --host 127.0.0.1 --port 18080 --base_dir . --auth_user cnl --auth_password ***"
    },
    {
      "title": "Cloudflared Processes",
      "content": "664476 /users/staff/dmi-dmi/kumar0002/bin/cloudflared tunnel --no-autoupdate --url http://127.0.0.1:18080"
    }
  ],
  "links": [
    {
      "label": "Public Live Dashboard",
      "url": "https://romance-auditor-spots-kijiji.trycloudflare.com",
      "health": "auth_required",
      "http_code": "401",
      "source": "cloudflared_log",
      "source_path": "logs/cloudflared_dashboard_20260211_144945.out"
    }
  ],
  "jobs": [
    {
      "dataset": "arc_c",
      "use_freeze": 1,
      "status": "done",
      "epoch": "25",
      "train_avg_loss": "2.585893348826598",
      "wrong_to_correct": "38",
      "correct_to_wrong": "40",
      "elapsed": "1:07:37",
      "log_path": "logs/train_arc_c_usefreeze1.log",
      "summary_path": "zero_ckpts/arc_c_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
    },
    {
      "dataset": "arc_c",
      "use_freeze": 0,
      "status": "done",
      "epoch": "25",
      "train_avg_loss": "1.3083139358742",
      "wrong_to_correct": "298",
      "correct_to_wrong": "254",
      "elapsed": "44:40.38",
      "log_path": "logs/train_arc_c_usefreeze0.log",
      "summary_path": "zero_ckpts/arc_c_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
    },
    {
      "dataset": "csqa",
      "use_freeze": 1,
      "status": "done",
      "epoch": "25",
      "train_avg_loss": "2.4547550374364793",
      "wrong_to_correct": "23",
      "correct_to_wrong": "32",
      "elapsed": "57:54.81",
      "log_path": "logs/train_csqa_usefreeze1.log",
      "summary_path": "zero_ckpts/csqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
    },
    {
      "dataset": "csqa",
      "use_freeze": 0,
      "status": "done",
      "epoch": "25",
      "train_avg_loss": "1.2850813132517158",
      "wrong_to_correct": "236",
      "correct_to_wrong": "257",
      "elapsed": "37:33.90",
      "log_path": "logs/train_csqa_usefreeze0.log",
      "summary_path": "zero_ckpts/csqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
    },
    {
      "dataset": "medqa",
      "use_freeze": 1,
      "status": "done",
      "epoch": "25",
      "train_avg_loss": "2.2436387252039323",
      "wrong_to_correct": "83",
      "correct_to_wrong": "82",
      "elapsed": "1:17:30",
      "log_path": "logs/train_medqa_usefreeze1.log",
      "summary_path": "zero_ckpts/medqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
    },
    {
      "dataset": "medqa",
      "use_freeze": 0,
      "status": "done",
      "epoch": "25",
      "train_avg_loss": "1.4639859721219466",
      "wrong_to_correct": "261",
      "correct_to_wrong": "264",
      "elapsed": "50:47.39",
      "log_path": "logs/train_medqa_usefreeze0.log",
      "summary_path": "zero_ckpts/medqa_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
    },
    {
      "dataset": "mmlu",
      "use_freeze": 1,
      "status": "done",
      "epoch": "25",
      "train_avg_loss": "2.5952079296872324",
      "wrong_to_correct": "54",
      "correct_to_wrong": "68",
      "elapsed": "1:21:03",
      "log_path": "logs/train_mmlu_usefreeze1.log",
      "summary_path": "zero_ckpts/mmlu_SmolLM2-360M-Instruct_lr1e-7_usefreeze1/summary.csv"
    },
    {
      "dataset": "mmlu",
      "use_freeze": 0,
      "status": "done",
      "epoch": "25",
      "train_avg_loss": "1.3213374216337592",
      "wrong_to_correct": "347",
      "correct_to_wrong": "331",
      "elapsed": "1:01:46",
      "log_path": "logs/train_mmlu_usefreeze0.log",
      "summary_path": "zero_ckpts/mmlu_SmolLM2-360M-Instruct_lr1e-7_usefreeze0/summary.csv"
    }
  ],
  "gpu": [
    {
      "gpu": "0",
      "name": "NVIDIA GeForce RTX 3090",
      "memory_used": "22713 MiB",
      "memory_total": "24576 MiB",
      "utilization": "22 %"
    },
    {
      "gpu": "1",
      "name": "NVIDIA GeForce RTX 3090",
      "memory_used": "9174 MiB",
      "memory_total": "24576 MiB",
      "utilization": "26 %"
    },
    {
      "gpu": "2",
      "name": "NVIDIA GeForce RTX 3090",
      "memory_used": "9174 MiB",
      "memory_total": "24576 MiB",
      "utilization": "20 %"
    },
    {
      "gpu": "3",
      "name": "NVIDIA GeForce RTX 3090",
      "memory_used": "9172 MiB",
      "memory_total": "24576 MiB",
      "utilization": "23 %"
    },
    {
      "gpu": "4",
      "name": "NVIDIA GeForce RTX 3090",
      "memory_used": "5788 MiB",
      "memory_total": "24576 MiB",
      "utilization": "94 %"
    },
    {
      "gpu": "5",
      "name": "NVIDIA GeForce RTX 3090",
      "memory_used": "9726 MiB",
      "memory_total": "24576 MiB",
      "utilization": "24 %"
    },
    {
      "gpu": "6",
      "name": "NVIDIA GeForce RTX 3090",
      "memory_used": "9172 MiB",
      "memory_total": "24576 MiB",
      "utilization": "29 %"
    },
    {
      "gpu": "7",
      "name": "NVIDIA GeForce RTX 3090",
      "memory_used": "9172 MiB",
      "memory_total": "24576 MiB",
      "utilization": "46 %"
    }
  ],
  "public_dashboard_url": "https://romance-auditor-spots-kijiji.trycloudflare.com",
  "public_dashboard_http_noauth": "401"
}
